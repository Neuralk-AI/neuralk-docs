"use strict";(globalThis.webpackChunkdocs_neuralk=globalThis.webpackChunkdocs_neuralk||[]).push([[9386],{1839:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>o,default:()=>h,frontMatter:()=>a,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"intro-draft","title":"API Reference  1","description":"The Neuralk API allows data scientists and companies to power their business applications with state-of-the-art prediction models and tools developed by the Neuralk AI team.","source":"@site/api-reference/intro-draft.md","sourceDirName":".","slug":"/intro-draft","permalink":"/api-reference/intro-draft","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":2,"frontMatter":{"sidebar_position":2}}');var t=i(4848),s=i(8453);const a={sidebar_position:2},o="API Reference  1",l={},c=[{value:"Neuralk AI Tabular Foundation Models",id:"neuralk-ai-tabular-foundation-models",level:2},{value:"NICL (Neuralk In-Context Learning)",id:"nicl-neuralk-in-context-learning",level:3},{value:"Limitations",id:"limitations",level:3},{value:"Data Preparation",id:"data-preparation",level:3},{value:"Maximising Correctness",id:"maximising-correctness",level:3}];function d(e){const n={em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",p:"p",strong:"strong",ul:"ul",...(0,s.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"api-reference--1",children:"API Reference  1"})}),"\n",(0,t.jsx)(n.p,{children:"The Neuralk API allows data scientists and companies to power their business applications with state-of-the-art prediction models and tools developed by the Neuralk AI team."}),"\n",(0,t.jsx)(n.h2,{id:"neuralk-ai-tabular-foundation-models",children:"Neuralk AI Tabular Foundation Models"}),"\n",(0,t.jsx)(n.h3,{id:"nicl-neuralk-in-context-learning",children:"NICL (Neuralk In-Context Learning)"}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"NICL"})," is designed for ",(0,t.jsx)(n.strong,{children:"tabular prediction tasks"})," (classification) where patterns can be inferred directly from the data distribution without extensive model tuning."]}),"\n",(0,t.jsxs)(n.p,{children:["NICL performs best on datasets with up to ",(0,t.jsx)(n.strong,{children:"250 features"})," and ",(0,t.jsx)(n.strong,{children:"15,000 samples"}),", offering reliable and consistent performance out of the box."]}),"\n",(0,t.jsxs)(n.p,{children:["For larger problems, NICL can scale to ",(0,t.jsx)(n.strong,{children:"1 million samples"})," and ",(0,t.jsx)(n.strong,{children:"500 features"}),", though performance and inference time may vary depending on hardware and input complexity."]}),"\n",(0,t.jsx)(n.p,{children:"NICL is ideal when you:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Need strong baseline performance without hyper-parameter tuning."}),"\n",(0,t.jsx)(n.li,{children:"Want a unified approach to handle mixed feature types."}),"\n",(0,t.jsx)(n.li,{children:"Are exploring new datasets and want fast iteration."}),"\n",(0,t.jsx)(n.li,{children:"Prefer interpretability and flexible prompting over black-box optimisation."}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"limitations",children:"Limitations"}),"\n",(0,t.jsx)(n.p,{children:"While NICL provides excellent generalisation across a wide range of datasets, there are a few important considerations:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Very high-dimensional"})," or ",(0,t.jsx)(n.strong,{children:"sparse"})," data (e.g., text bag-of-words, one-hot expansions) may require preprocessing to achieve optimal performance."]}),"\n"]}),"\n",(0,t.jsxs)(n.li,{children:["\n",(0,t.jsxs)(n.p,{children:["NICL is ",(0,t.jsx)(n.strong,{children:"not optimised through hyper-parameter search"}),"\u2014its strength lies in generalisation and prompt conditioning rather than parameter tuning."]}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"data-preparation",children:"Data Preparation"}),"\n",(0,t.jsxs)(n.p,{children:["NICL is designed to work with ",(0,t.jsx)(n.strong,{children:"minimal preprocessing"}),". In most cases, you can pass your dataset as a clean tabular structure (e.g., pandas DataFrame) and obtain strong performance."]}),"\n",(0,t.jsx)(n.p,{children:"However, you can improve accuracy and stability by following a few simple practices:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Handle ",(0,t.jsx)(n.strong,{children:"missing values"})," (imputation or explicit missing indicators)."]}),"\n",(0,t.jsxs)(n.li,{children:["Encode ",(0,t.jsx)(n.strong,{children:"categorical features"})," as integers consistently across training and inference."]}),"\n",(0,t.jsx)(n.li,{children:"Keep feature semantics consistent between training and prediction."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Expert-based preprocessing or domain-specific feature engineering can further enhance results, but NICL is intentionally built to work well \u201cas is.\u201d"})}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsx)(n.h3,{id:"maximising-correctness",children:"Maximising Correctness"}),"\n",(0,t.jsxs)(n.p,{children:["Unlike traditional ML models, NICL does not rely on hyper-parameter tuning or fine-tuning. Instead, its performance can often be improved through ",(0,t.jsx)(n.strong,{children:"prompt design"})," and ",(0,t.jsx)(n.strong,{children:"context specification"}),"."]}),"\n",(0,t.jsx)(n.p,{children:"When working with NICL:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["Include ",(0,t.jsx)(n.strong,{children:"representative samples"})," to help NICL infer feature importance and relationships."]}),"\n",(0,t.jsx)(n.li,{children:"Experiment with context to help NICL focus on the most relevant aspects of your data."}),"\n"]}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.em,{children:"Think of NI"})})]})}function h(e={}){const{wrapper:n}={...(0,s.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>a,x:()=>o});var r=i(6540);const t={},s=r.createContext(t);function a(e){const n=r.useContext(s);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:a(e.components),r.createElement(s.Provider,{value:n},e.children)}}}]);